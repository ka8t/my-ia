<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <title>Ollama - LLM Local</title>
</head>
<body>
    <h1>Ollama - Serveur LLM Local</h1>

    <h2>Qu'est-ce qu'Ollama ?</h2>
    <p>
        Ollama est un outil qui permet d'exécuter des modèles de langage (LLM)
        en local sur votre machine, sans dépendre de services cloud.
    </p>

    <h2>Modèles supportés</h2>
    <ul>
        <li>Mistral 7B - Modèle compact et performant</li>
        <li>Llama 3.2 - Dernier modèle de Meta</li>
        <li>Gemma - Modèle de Google</li>
        <li>CodeLlama - Spécialisé pour le code</li>
    </ul>

    <h2>Avantages</h2>
    <table border="1">
        <tr>
            <th>Aspect</th>
            <th>Avantage</th>
        </tr>
        <tr>
            <td>Confidentialité</td>
            <td>Données restent en local</td>
        </tr>
        <tr>
            <td>Coût</td>
            <td>Pas de frais API</td>
        </tr>
        <tr>
            <td>Latence</td>
            <td>Pas de latence réseau</td>
        </tr>
    </table>

    <script>
        // Ce script ne devrait pas être extrait
        console.log("Hidden script content");
    </script>

    <p>Pour plus d'informations, visitez <a href="https://ollama.ai">ollama.ai</a></p>
</body>
</html>
