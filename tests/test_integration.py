"""
Tests d'int√©gration end-to-end pour MY-IA

Ces tests v√©rifient le workflow complet du syst√®me:
1. Ingestion de documents ‚Üí ChromaDB
2. Requ√™te utilisateur ‚Üí RAG ‚Üí R√©ponse Ollama
3. Streaming de r√©ponse
4. Gestion des sessions

‚ö†Ô∏è IMPORTANT: Ces tests n√©cessitent:
- Ollama en cours d'ex√©cution
- ChromaDB en cours d'ex√©cution
- Mod√®le Ollama t√©l√©charg√© (mistral:7b)
- Mod√®le d'embeddings (nomic-embed-text)

Pour ex√©cuter ces tests:
    pytest -m integration -v

Pour les exclure:
    pytest -m "not integration" -v
"""
import pytest
import asyncio
import tempfile
import json
from pathlib import Path
import httpx


# ============================================================================
# TESTS E2E WORKFLOW COMPLET
# ============================================================================

@pytest.mark.integration
@pytest.mark.slow
@pytest.mark.asyncio
class TestEndToEndWorkflow:
    """Tests du workflow complet: ingestion ‚Üí query ‚Üí response"""

    async def test_complete_rag_workflow(
        self,
        async_client: httpx.AsyncClient,
        test_api_key: str
    ):
        """
        Test complet du workflow RAG:
        1. V√©rifier que l'API est accessible
        2. Faire une requ√™te /chat
        3. V√©rifier qu'une r√©ponse est g√©n√©r√©e
        4. V√©rifier que des sources sont retourn√©es
        """
        # 1. Health check
        response = await async_client.get("/health")
        assert response.status_code == 200

        health_data = response.json()

        # V√©rifier que les services sont disponibles
        if not health_data.get("ollama") or not health_data.get("chroma"):
            pytest.skip("Services Ollama ou ChromaDB non disponibles")

        # 2. Requ√™te /chat
        chat_request = {
            "query": "Qu'est-ce que le RAG ?",
            "session_id": "e2e-test-session"
        }

        response = await async_client.post(
            "/chat",
            json=chat_request,
            headers={"X-API-Key": test_api_key},
            timeout=60.0
        )

        assert response.status_code == 200
        data = response.json()

        # 3. V√©rifier la structure de la r√©ponse
        assert "response" in data
        assert "sources" in data
        assert "session_id" in data

        # 4. V√©rifier le contenu
        assert isinstance(data["response"], str)
        assert len(data["response"]) > 0
        assert data["session_id"] == "e2e-test-session"

        # Les sources peuvent √™tre None si pas de documents index√©s
        if data["sources"]:
            assert isinstance(data["sources"], list)

    async def test_assistant_mode_workflow(
        self,
        async_client: httpx.AsyncClient,
        test_api_key: str
    ):
        """
        Test du mode Assistant (orient√© t√¢ches)
        """
        # Health check d'abord
        health = await async_client.get("/health")
        if not health.json().get("ollama"):
            pytest.skip("Ollama non disponible")

        # Requ√™te assistant
        request_data = {
            "query": "Donne-moi 3 √©tapes pour cr√©er un chatbot",
            "session_id": "assistant-test"
        }

        response = await async_client.post(
            "/assistant",
            json=request_data,
            headers={"X-API-Key": test_api_key},
            timeout=60.0
        )

        assert response.status_code == 200
        data = response.json()

        assert "response" in data
        assert len(data["response"]) > 0


@pytest.mark.integration
@pytest.mark.slow
@pytest.mark.asyncio
class TestStreamingWorkflow:
    """Tests du streaming de r√©ponses"""

    async def test_chat_streaming_e2e(
        self,
        async_client: httpx.AsyncClient,
        test_api_key: str
    ):
        """
        Test du streaming end-to-end:
        1. Initier un stream
        2. Recevoir des chunks progressivement
        3. V√©rifier le format NDJSON
        """
        # Health check
        health = await async_client.get("/health")
        if not health.json().get("ollama"):
            pytest.skip("Ollama non disponible")

        # Initier le streaming
        request_data = {
            "query": "Explique en une phrase ce qu'est l'IA",
            "session_id": "stream-test"
        }

        async with async_client.stream(
            "POST",
            "/chat/stream",
            json=request_data,
            headers={"X-API-Key": test_api_key},
            timeout=60.0
        ) as response:
            assert response.status_code == 200
            assert response.headers["content-type"] == "application/x-ndjson"

            chunks_received = 0
            full_response = ""

            async for line in response.aiter_lines():
                if line.strip():
                    # V√©rifier que c'est du JSON valide
                    try:
                        chunk_data = json.loads(line)
                        chunks_received += 1

                        # Accumuler la r√©ponse
                        if "response" in chunk_data:
                            full_response += chunk_data["response"]

                        # V√©rifier qu'on a bien un flag "done"
                        if chunk_data.get("done"):
                            break

                    except json.JSONDecodeError:
                        pytest.fail(f"Invalid JSON chunk: {line}")

            # V√©rifier qu'on a re√ßu des chunks
            assert chunks_received > 0, "Aucun chunk re√ßu"
            assert len(full_response) > 0, "R√©ponse vide"


@pytest.mark.integration
@pytest.mark.slow
@pytest.mark.asyncio
class TestIngestionWorkflow:
    """Tests du workflow d'ingestion de documents"""

    async def test_ingest_and_query_workflow(
        self,
        async_client: httpx.AsyncClient,
        test_api_key: str,
        tmp_path: Path
    ):
        """
        Test complet d'ingestion:
        1. Cr√©er un document de test
        2. L'ing√©rer dans ChromaDB (via script ingest)
        3. Faire une requ√™te qui devrait utiliser ce document
        4. V√©rifier que le document est dans les sources

        Note: Ce test n√©cessite d'ex√©cuter le script d'ingestion
        ou d'utiliser l'API d'ingestion si elle existe
        """
        # Pour ce test, on va v√©rifier qu'une requ√™te utilise bien
        # les documents existants dans la base

        # Health check
        health = await async_client.get("/health")
        if not health.json().get("ollama") or not health.json().get("chroma"):
            pytest.skip("Services non disponibles")

        # Requ√™te sp√©cifique qui devrait trouver des sources
        request_data = {
            "query": "Qu'est-ce qui est index√© dans la base de donn√©es ?",
            "session_id": "ingest-test"
        }

        response = await async_client.post(
            "/chat",
            json=request_data,
            headers={"X-API-Key": test_api_key},
            timeout=60.0
        )

        assert response.status_code == 200
        data = response.json()

        # Si des documents sont index√©s, on devrait avoir des sources
        # Sinon, le test passe quand m√™me (base vide)
        assert "sources" in data
        if data["sources"] is not None:
            assert isinstance(data["sources"], list)


@pytest.mark.integration
@pytest.mark.slow
@pytest.mark.asyncio
class TestErrorHandling:
    """Tests de gestion d'erreur en conditions r√©elles"""

    async def test_invalid_query_handling(
        self,
        async_client: httpx.AsyncClient,
        test_api_key: str
    ):
        """V√©rifier la gestion d'une query invalide"""
        # Query vide
        response = await async_client.post(
            "/chat",
            json={"query": "", "session_id": "test"},
            headers={"X-API-Key": test_api_key}
        )

        # Devrait √©chouer la validation
        assert response.status_code == 422

    async def test_missing_api_key(
        self,
        async_client: httpx.AsyncClient
    ):
        """V√©rifier le rejet sans API key"""
        response = await async_client.post(
            "/chat",
            json={"query": "Test", "session_id": "test"}
        )

        assert response.status_code == 401

    async def test_invalid_api_key(
        self,
        async_client: httpx.AsyncClient
    ):
        """V√©rifier le rejet avec mauvaise API key"""
        response = await async_client.post(
            "/chat",
            json={"query": "Test", "session_id": "test"},
            headers={"X-API-Key": "invalid-key-123"}
        )

        assert response.status_code == 401


@pytest.mark.integration
@pytest.mark.slow
@pytest.mark.asyncio
class TestPerformance:
    """Tests de performance basiques"""

    async def test_chat_response_time(
        self,
        async_client: httpx.AsyncClient,
        test_api_key: str
    ):
        """
        V√©rifier que les r√©ponses arrivent dans un d√©lai raisonnable
        Note: Peut √™tre lent selon la machine et le mod√®le
        """
        import time

        # Health check
        health = await async_client.get("/health")
        if not health.json().get("ollama"):
            pytest.skip("Ollama non disponible")

        start_time = time.time()

        response = await async_client.post(
            "/chat",
            json={"query": "Bonjour", "session_id": "perf-test"},
            headers={"X-API-Key": test_api_key},
            timeout=120.0  # 2 minutes max
        )

        elapsed_time = time.time() - start_time

        assert response.status_code == 200

        # Log du temps de r√©ponse (pour monitoring)
        print(f"\n‚è±Ô∏è  Temps de r√©ponse: {elapsed_time:.2f}s")

        # V√©rification souple (peut varier selon le hardware)
        # On v√©rifie juste que √ßa ne timeout pas
        assert elapsed_time < 120.0

    async def test_concurrent_requests(
        self,
        async_client: httpx.AsyncClient,
        test_api_key: str
    ):
        """
        Tester plusieurs requ√™tes concurrentes
        """
        # Health check
        health = await async_client.get("/health")
        if not health.json().get("ollama"):
            pytest.skip("Ollama non disponible")

        # Cr√©er 3 requ√™tes concurrentes
        async def make_request(session_id: str):
            response = await async_client.post(
                "/test",  # Endpoint plus simple sans RAG
                json={"query": f"Test {session_id}", "session_id": session_id},
                headers={"X-API-Key": test_api_key},
                timeout=120.0
            )
            return response.status_code

        # Lancer 3 requ√™tes en parall√®le
        results = await asyncio.gather(
            make_request("concurrent-1"),
            make_request("concurrent-2"),
            make_request("concurrent-3")
        )

        # Toutes devraient r√©ussir
        assert all(status == 200 for status in results)


@pytest.mark.integration
@pytest.mark.slow
class TestServicesIntegration:
    """Tests d'int√©gration avec les services externes"""

    def test_ollama_connection(self, test_ollama_host: str):
        """V√©rifier la connexion √† Ollama"""
        import requests

        try:
            response = requests.get(f"{test_ollama_host}/api/tags", timeout=5)
            assert response.status_code == 200
        except Exception as e:
            pytest.skip(f"Ollama non accessible: {e}")

    def test_chromadb_connection(self, test_chroma_host: str):
        """V√©rifier la connexion √† ChromaDB"""
        import requests

        try:
            response = requests.get(f"{test_chroma_host}/api/v1/heartbeat", timeout=5)
            assert response.status_code == 200
        except Exception as e:
            pytest.skip(f"ChromaDB non accessible: {e}")


@pytest.mark.integration
@pytest.mark.slow
@pytest.mark.asyncio
class TestRateLimitingIntegration:
    """Tests de rate limiting en conditions r√©elles"""

    @pytest.mark.skip(reason="Peut prendre du temps et affecter d'autres tests")
    async def test_rate_limit_enforcement(
        self,
        async_client: httpx.AsyncClient,
        test_api_key: str
    ):
        """
        V√©rifier que le rate limiting fonctionne
        Note: D√©sactiv√© par d√©faut car peut √™tre long
        """
        # Faire beaucoup de requ√™tes rapidement
        responses = []

        for i in range(35):  # Plus que la limite de 30/minute
            try:
                response = await async_client.post(
                    "/test",
                    json={"query": f"Test {i}", "session_id": f"rate-{i}"},
                    headers={"X-API-Key": test_api_key},
                    timeout=5.0
                )
                responses.append(response.status_code)
            except httpx.TimeoutException:
                responses.append(0)

        # Au moins une devrait √™tre rate limited (429)
        # Ou toutes passent si le rate limiter est d√©sactiv√© en test
        rate_limited_count = responses.count(429)
        print(f"\nüö¶ Requ√™tes rate limited: {rate_limited_count}/35")


# ============================================================================
# FIXTURES SP√âCIFIQUES AUX TESTS D'INT√âGRATION
# ============================================================================

@pytest.fixture(scope="module")
def integration_setup():
    """
    Setup sp√©cifique pour les tests d'int√©gration
    Peut √™tre utilis√© pour initialiser des donn√©es de test
    """
    # Setup
    print("\nüîß Setup des tests d'int√©gration...")

    yield

    # Teardown
    print("\nüßπ Cleanup des tests d'int√©gration...")


@pytest.fixture
def sample_test_document(tmp_path: Path) -> Path:
    """Cr√©er un document de test pour l'ingestion"""
    doc_file = tmp_path / "test_document.md"
    content = """
    # Document de Test

    Ce document sert √† tester le syst√®me RAG.

    ## Section 1
    Le RAG (Retrieval-Augmented Generation) combine recherche et g√©n√©ration.

    ## Section 2
    ChromaDB est une base de donn√©es vectorielle.
    """

    doc_file.write_text(content, encoding="utf-8")
    return doc_file
