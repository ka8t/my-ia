# Tests d'Int√©gration MY-IA

Ce document explique comment configurer et ex√©cuter les tests d'int√©gration end-to-end.

## Pr√©requis

Les tests d'int√©gration n√©cessitent que les services suivants soient **en cours d'ex√©cution** :

### 1. Ollama
```bash
# V√©rifier qu'Ollama est en cours
curl http://localhost:11434/api/tags

# D√©marrer Ollama si n√©cessaire
ollama serve

# T√©l√©charger les mod√®les requis
ollama pull mistral:7b
ollama pull nomic-embed-text
```

### 2. ChromaDB
```bash
# Avec Docker Compose (recommand√©)
docker compose up -d chroma

# V√©rifier que ChromaDB est accessible
curl http://localhost:8000/api/v1/heartbeat
```

### 3. API MY-IA (optionnel)
```bash
# Si vous testez l'API d√©ploy√©e
docker compose up -d app
```

## Configuration

### Variables d'environnement

Les tests utilisent ces variables (d√©finies dans `conftest.py`) :

```bash
export OLLAMA_HOST="http://localhost:11434"
export CHROMA_HOST="http://localhost:8000"
export API_KEY="test-api-key-12345"
export MODEL_NAME="mistral:7b"
export EMBED_MODEL="nomic-embed-text"
```

### Donn√©es de test

Pour les tests d'ingestion, vous pouvez cr√©er des documents dans `datasets/` :

```bash
mkdir -p datasets
echo "# Test Document\n\nCe document teste le RAG." > datasets/test.md
```

## Ex√©cution des tests

### Tous les tests d'int√©gration

```bash
pytest -m integration -v
```

### Tests d'int√©gration avec output d√©taill√©

```bash
pytest -m integration -v -s
```

### Tests sp√©cifiques

```bash
# Workflow complet
pytest tests/test_integration.py::TestEndToEndWorkflow -v

# Streaming
pytest tests/test_integration.py::TestStreamingWorkflow -v

# Performance
pytest tests/test_integration.py::TestPerformance -v
```

### Avec timeout custom

```bash
pytest -m integration -v --timeout=300
```

## Structure des tests

### TestEndToEndWorkflow
- `test_complete_rag_workflow` : Test du workflow complet RAG
- `test_assistant_mode_workflow` : Test du mode Assistant

**Ce qui est test√© :**
1. Health check des services
2. Requ√™te /chat avec API key
3. V√©rification de la r√©ponse
4. V√©rification des sources retourn√©es

### TestStreamingWorkflow
- `test_chat_streaming_e2e` : Test du streaming de bout en bout

**Ce qui est test√© :**
1. Initiation du stream
2. R√©ception de chunks NDJSON
3. Accumulation de la r√©ponse
4. Flag "done" final

### TestIngestionWorkflow
- `test_ingest_and_query_workflow` : Test ingestion ‚Üí query

**Ce qui est test√© :**
1. Existence de documents dans ChromaDB
2. Requ√™te utilisant les documents
3. Sources dans la r√©ponse

### TestErrorHandling
- `test_invalid_query_handling` : Query invalide
- `test_missing_api_key` : Sans API key
- `test_invalid_api_key` : Mauvaise API key

**Ce qui est test√© :**
- Codes d'erreur appropri√©s (401, 422)
- Messages d'erreur corrects

### TestPerformance
- `test_chat_response_time` : Temps de r√©ponse
- `test_concurrent_requests` : Requ√™tes concurrentes

**Ce qui est test√© :**
- Temps de r√©ponse < 2 minutes
- Support de requ√™tes concurrentes

### TestServicesIntegration
- `test_ollama_connection` : Connexion Ollama
- `test_chromadb_connection` : Connexion ChromaDB

**Ce qui est test√© :**
- Accessibilit√© des services
- Endpoints de health check

## Debugging

### Logs d√©taill√©s

```bash
pytest -m integration -v -s --log-cli-level=DEBUG
```

### Capturer les prints

```bash
pytest -m integration -v -s
```

### Mode interactif en cas d'√©chec

```bash
pytest -m integration -v --pdb
```

## Probl√®mes courants

### ‚ùå "Ollama non disponible"

**Solution :**
```bash
# V√©rifier qu'Ollama tourne
ps aux | grep ollama

# D√©marrer Ollama
ollama serve

# V√©rifier l'accessibilit√©
curl http://localhost:11434/api/tags
```

### ‚ùå "ChromaDB non disponible"

**Solution :**
```bash
# V√©rifier le conteneur
docker ps | grep chroma

# Red√©marrer ChromaDB
docker compose restart chroma

# V√©rifier les logs
docker compose logs chroma
```

### ‚ùå "Timeout lors des tests"

**Causes possibles :**
- Mod√®le Ollama trop lent pour le hardware
- Ollama n'a pas de GPU
- Mod√®le non t√©l√©charg√©

**Solutions :**
```bash
# Augmenter le timeout
pytest -m integration -v --timeout=600

# Utiliser un mod√®le plus petit
export MODEL_NAME="tinyllama"
ollama pull tinyllama

# V√©rifier que le mod√®le est charg√©
ollama list
```

### ‚ùå "Tests √©chouent mais services fonctionnent"

**Debug :**
```bash
# Tester manuellement l'API
curl -X POST http://localhost:8080/chat \
  -H "Content-Type: application/json" \
  -H "X-API-Key: test-api-key-12345" \
  -d '{"query":"Test","session_id":"debug"}'

# V√©rifier les logs
docker compose logs app
```

## M√©triques de performance

Les tests de performance affichent des m√©triques :

```
‚è±Ô∏è  Temps de r√©ponse: 12.34s
üö¶ Requ√™tes rate limited: 5/35
```

Ces m√©triques peuvent varier selon :
- Le hardware (CPU, RAM, GPU)
- Le mod√®le utilis√©
- La charge du syst√®me

## CI/CD

Dans un environnement CI/CD, vous pouvez :

### Option 1 : Utiliser des services r√©els

```yaml
services:
  ollama:
    image: ollama/ollama
  chromadb:
    image: chromadb/chroma
```

### Option 2 : Mocker les services

```bash
# Ex√©cuter seulement les tests unitaires en CI
pytest -m "not integration" -v
```

### Option 3 : Tests d'int√©gration conditionnels

```bash
# Skip si services non disponibles
pytest -m integration -v --skip-if-services-down
```

## Bonnes pratiques

1. **Isoler les tests** : Chaque test doit √™tre ind√©pendant
2. **Nettoyer apr√®s** : Supprimer les donn√©es de test cr√©√©es
3. **Timeouts g√©n√©reux** : Les tests d'int√©gration peuvent √™tre lents
4. **Skip si services down** : Utiliser `pytest.skip()` si services indisponibles
5. **Logs clairs** : Afficher des messages utiles en cas d'√©chec

## Exemple de workflow complet

```bash
# 1. D√©marrer les services
docker compose up -d ollama chroma

# 2. Attendre qu'ils soient pr√™ts
sleep 10

# 3. T√©l√©charger les mod√®les
docker compose exec ollama ollama pull mistral:7b
docker compose exec ollama ollama pull nomic-embed-text

# 4. Optionnel : Ing√©rer des documents de test
docker compose exec app python app/ingest.py

# 5. Lancer les tests
pytest -m integration -v

# 6. Nettoyer
docker compose down
```

## Monitoring des tests

Vous pouvez monitorer les tests avec :

```bash
# G√©n√©ration de rapport HTML
pytest -m integration -v --html=report.html --self-contained-html

# G√©n√©ration de rapport JSON
pytest -m integration -v --json-report --json-report-file=report.json
```

## Ressources

- [Documentation Ollama](https://ollama.ai/docs)
- [Documentation ChromaDB](https://docs.trychroma.com/)
- [pytest-asyncio](https://pytest-asyncio.readthedocs.io/)
