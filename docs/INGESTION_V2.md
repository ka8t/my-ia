# SystÃ¨me d'Ingestion AvancÃ© v2.0

## ğŸ“‹ Vue d'ensemble

Le nouveau systÃ¨me d'ingestion v2 utilise les meilleures pratiques 2025 pour le parsing de documents et le chunking sÃ©mantique dans les pipelines RAG.

## ğŸš€ FonctionnalitÃ©s principales

### 1. Parsing multi-format avec Unstructured.io

**Formats supportÃ©s :**
- **Documents** : PDF, DOCX, DOC, TXT, MD, HTML
- **Feuilles de calcul** : XLSX, XLS, CSV
- **PrÃ©sentations** : PPTX, PPT
- **DonnÃ©es structurÃ©es** : JSON, JSONL
- **Images** : PNG, JPG, JPEG (avec OCR automatique)

**StratÃ©gies de parsing :**
- `auto` : DÃ©tection automatique (dÃ©faut)
- `fast` : Rapide, pour documents simples
- `hi_res` : Haute rÃ©solution, extraction optimale
- `ocr_only` : Forcer l'OCR pour images/PDFs scannÃ©s

### 2. Chunking sÃ©mantique intelligent

**3 stratÃ©gies disponibles :**

#### a) Recursive Character Splitting (dÃ©faut)
- Respecte la structure naturelle du texte
- SÃ©parateurs : paragraphes > phrases > mots
- PrÃ©serve la cohÃ©sion sÃ©mantique
- Taille configurable (dÃ©faut : 1000 caractÃ¨res, overlap : 200)

#### b) By Title
- DÃ©coupe par structure du document (titres, sections)
- IdÃ©al pour documents structurÃ©s
- PrÃ©serve la hiÃ©rarchie

#### c) Markdown Header Splitting
- SpÃ©cialisÃ© pour fichiers Markdown
- DÃ©coupe par headers (#, ##, ###)
- MÃ©tadonnÃ©es de headers prÃ©servÃ©es

### 3. DÃ©duplication automatique

- Hash SHA256 de chaque document
- VÃ©rification avant indexation
- Skip automatique des duplicatas
- Ã‰conomie de ressources et d'espace

### 4. MÃ©tadonnÃ©es enrichies

Chaque chunk contient :
```json
{
  "filename": "document.pdf",
  "file_extension": ".pdf",
  "file_size": 524288,
  "created_at": "2025-01-15T10:30:00",
  "modified_at": "2025-01-15T11:00:00",
  "file_path": "/path/to/document.pdf",
  "document_hash": "abc123...",
  "chunk_index": 0,
  "total_chunks": 42,
  "chunk_type": "text",
  "indexed_at": "2025-01-15T11:05:00",
  "ingestion_version": "2.0"
}
```

### 5. Extraction de tables

- DÃ©tection automatique des tables dans les documents
- Structure prÃ©servÃ©e
- Indexation sÃ©parÃ©e pour recherche optimale

### 6. OCR pour images

- Tesseract OCR intÃ©grÃ©
- Support franÃ§ais et anglais
- Extraction de texte depuis images/PDFs scannÃ©s

### 7. Pipeline asynchrone optimisÃ©

- Traitement par batches
- GÃ©nÃ©ration d'embeddings parallÃ©lisÃ©e
- Gestion de progression en temps rÃ©el
- OptimisÃ© pour gros volumes

## ğŸ”§ Configuration

Variables d'environnement :

```bash
# Chunking
CHUNK_SIZE=1000                    # Taille des chunks (caractÃ¨res)
CHUNK_OVERLAP=200                  # Chevauchement entre chunks
CHUNKING_STRATEGY=semantic         # 'semantic', 'recursive', 'by_title'

# Chemins
DATASETS_DIR=/app/datasets         # Dossier source pour ingestion batch
CHROMA_PATH=/chroma/chroma        # Stockage ChromaDB
```

## ğŸ“¡ API Endpoints

### POST /upload/v2

Nouvel endpoint d'upload avancÃ©.

**ParamÃ¨tres :**
- `file` (FormData) : Fichier Ã  uploader
- `parsing_strategy` (query, optionnel) : 'auto', 'fast', 'hi_res', 'ocr_only'
- `skip_duplicates` (query, optionnel) : true/false (dÃ©faut: true)
- `X-API-Key` (header) : ClÃ© API

**Exemple avec curl :**
```bash
curl -X POST http://localhost:8080/upload/v2 \
  -H "X-API-Key: change-me-in-production" \
  -F "file=@document.pdf"
```

**Exemple avec parsing haute rÃ©solution :**
```bash
curl -X POST "http://localhost:8080/upload/v2?parsing_strategy=hi_res" \
  -H "X-API-Key: change-me-in-production" \
  -F "file=@complex_document.pdf"
```

**RÃ©ponse :**
```json
{
  "success": true,
  "filename": "document.pdf",
  "chunks_indexed": 42,
  "message": "Fichier 'document.pdf' indexÃ© avec succÃ¨s (42 chunks, 3 tables dÃ©tectÃ©es)"
}
```

### POST /upload (legacy)

Ancien endpoint maintenu pour compatibilitÃ© ascendante.
Utilise le systÃ¨me d'ingestion simple (ingest.py).

## ğŸ”„ Migration depuis v1

Les deux systÃ¨mes coexistent :
- `/upload` utilise l'ancien systÃ¨me (ingest.py)
- `/upload/v2` utilise le nouveau systÃ¨me (ingest_v2.py)

Le frontend utilise maintenant `/upload/v2` par dÃ©faut.

## ğŸ› ï¸ Utilisation en ligne de commande

### Ingestion d'un dossier complet

```bash
docker compose run --rm app python ingest_v2.py
```

Cela ingÃ¨re tous les documents du dossier `/app/datasets` (dÃ©fini par `DATASETS_DIR`).

### Ingestion programmÃ©e

CrÃ©er un workflow N8N ou un cron job pour ingestion rÃ©guliÃ¨re :

```bash
# Tous les jours Ã  2h du matin
0 2 * * * docker compose run --rm app python ingest_v2.py
```

## ğŸ“Š Comparaison v1 vs v2

| FonctionnalitÃ© | v1 (ingest.py) | v2 (ingest_v2.py) |
|----------------|----------------|-------------------|
| **Formats** | PDF, TXT, MD, HTML, JSONL | + DOCX, XLSX, PPTX, Images |
| **Chunking** | Fixe (900 chars) | SÃ©mantique intelligent |
| **Parsing** | PyMuPDF, BeautifulSoup | Unstructured.io |
| **OCR** | âŒ | âœ… Tesseract |
| **Tables** | âŒ | âœ… Extraction dÃ©diÃ©e |
| **DÃ©duplication** | âŒ | âœ… Hash SHA256 |
| **MÃ©tadonnÃ©es** | Basiques | Enrichies |
| **Versioning** | âŒ | âœ… Hash + timestamps |
| **Performance** | Bonne | Excellente (async) |

## ğŸ¯ Best Practices

### 1. Choix de la stratÃ©gie de chunking

- **Documents structurÃ©s** (rapports, documentation) â†’ `by_title`
- **Documents Markdown** â†’ `markdown`
- **Documents variÃ©s** â†’ `semantic` (dÃ©faut)

### 2. Choix de la stratÃ©gie de parsing

- **Documents standards** â†’ `auto` (dÃ©faut)
- **Performances prioritaires** â†’ `fast`
- **QualitÃ© maximale** â†’ `hi_res`
- **PDFs scannÃ©s/images** â†’ `ocr_only`

### 3. Optimisation des performances

```python
# Variables d'environnement
CHUNK_SIZE=800           # Chunks plus petits = recherche plus prÃ©cise
CHUNK_OVERLAP=150        # Overlap minimal pour performance
```

### 4. DÃ©duplication

Toujours activÃ© par dÃ©faut. DÃ©sactiver uniquement si :
- RÃ©indexation forcÃ©e nÃ©cessaire
- Tests et dÃ©veloppement

## ğŸ” Debugging

Logs dÃ©taillÃ©s disponibles :

```bash
# Voir les logs du service app
docker compose logs -f app

# Filtrer pour ingestion seulement
docker compose logs -f app | grep -E "(Parsing|Ingestion|chunks)"
```

Niveau de log configurable :
```bash
LOG_LEVEL=DEBUG  # DEBUG, INFO, WARNING, ERROR
```

## ğŸš§ Limitations connues

1. **Taille maximale** : Fichiers > 100MB peuvent Ãªtre lents
2. **OCR** : QualitÃ© dÃ©pend de la qualitÃ© de l'image source
3. **Tables complexes** : Tableaux trÃ¨s imbriquÃ©s peuvent perdre structure
4. **Langues OCR** : FranÃ§ais et anglais uniquement (configurable)

## ğŸ“š RÃ©fÃ©rences

- [Unstructured.io Documentation](https://unstructured-io.github.io/unstructured/)
- [LangChain Text Splitters](https://python.langchain.com/docs/modules/data_connection/document_transformers/)
- [Best Chunking Strategies for RAG 2025](https://www.firecrawl.dev/blog/best-chunking-strategies-rag-2025)
- [ChromaDB Documentation](https://docs.trychroma.com/)

## ğŸ¤ Contribution

Pour amÃ©liorer le systÃ¨me d'ingestion :

1. Tester de nouveaux formats
2. Ajuster les paramÃ¨tres de chunking
3. Reporter les bugs via GitHub Issues
4. Proposer de nouvelles fonctionnalitÃ©s

---

**Version** : 2.0.0
**Date** : DÃ©cembre 2025
**Auteur** : MY-IA Team
