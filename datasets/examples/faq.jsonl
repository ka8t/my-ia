{"id": "deploy-001", "text": "Pour déployer l'application : 1) Exécuter docker compose up -d pour lancer tous les services (Ollama, ChromaDB, PostgreSQL, N8N et l'API), 2) Vérifier les logs avec docker compose logs -f pour s'assurer qu'il n'y a pas d'erreur, 3) Tester l'endpoint /health pour confirmer que tous les services sont opérationnels. Le déploiement prend généralement 2-3 minutes.", "metadata": {"source": "ops-manual", "tags": ["deployment", "docker"]}}
{"id": "n8n-001", "text": "N8N est un outil d'automatisation de workflows open-source. Interface accessible sur le port 5678. Identifiants par défaut: admin / change-me-in-production (à changer en production!). Permet de créer des workflows automatisés qui peuvent appeler l'API de l'IA pour traiter des documents, répondre à des emails, générer du contenu, etc.", "metadata": {"source": "n8n-manual", "tags": ["n8n", "automation"]}}
{"id": "deploy-002", "text": "Configuration des variables d'environnement : OLLAMA_HOST définit l'URL du service Ollama (ex: http://ollama:11434), CHROMA_HOST pour ChromaDB (ex: http://chroma:8000), MODEL_NAME pour le modèle LLM à utiliser (ex: llama3.1:8b), EMBED_MODEL pour le modèle d'embeddings (ex: nomic-embed-text), TOP_K pour le nombre de documents à récupérer (défaut: 4).", "metadata": {"source": "ops-manual", "tags": ["configuration", "environment"]}}
{"id": "incident-001", "text": "Procédure en cas de panne de base de données : 1) Vérifier l'état des conteneurs avec docker compose ps, 2) Consulter les logs du service concerné (chroma ou postgres) avec docker compose logs <service>, 3) Redémarrer le service avec docker compose restart <service>, 4) Si le problème persiste, vérifier l'espace disque disponible avec df -h, 5) En dernier recours, restaurer depuis le dernier backup avec le script de restauration.", "metadata": {"source": "runbook", "priority": "P1", "tags": ["incident", "database"]}}
{"id": "models-001", "text": "Modèles LLM disponibles : llama3.1:8b (recommandé, bon équilibre performance/qualité), mistral:7b (plus rapide), qwen2.5:7b (performant en multilangue). Pour télécharger un modèle : docker exec -it ollama ollama pull <model-name>. Temps de téléchargement : 5-10 minutes selon la connexion.", "metadata": {"source": "documentation", "tags": ["models", "configuration"]}}